{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-setup.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/InnovArul/nettutorial/blob/master/practice-playground/pytorch_setup.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "uYZCCoUofk7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "65c1f80d-5c81-4dc5-b31d-df0c95132a26"
      },
      "cell_type": "code",
      "source": [
        "# install torch\n",
        "!pip3 install torchvision\n",
        "\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "import os\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print(os.listdir('drive/'))\n",
        "\n",
        "# check torch\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 10.5MB/s \n",
            "\u001b[?25hCollecting torch (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    43% |██████████████                  | 212.7MB 34.4MB/s eta 0:00:08"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 484.0MB 25kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5b2aa000 @  0x7f9f84d861c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: pillow, torch, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.2.0 torch-0.4.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jUaTNKuDicDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e626ae89-f9c8-42b8-ccb3-a46482aa4d45"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 10 07:32:32 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   28C    P8    29W / 149W |     11MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PWi9wPA2iewv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "1efa4ad6-863d-4a70-ae4f-8feb0de4db97"
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn(33, 100) # segmentation fault\n",
        "print(torch.svd(x))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[-0.0499, -0.1870,  0.2007,  ...,  0.2286, -0.0100, -0.1045],\n",
            "        [-0.2578,  0.1951,  0.0353,  ...,  0.0836,  0.2268, -0.0686],\n",
            "        [ 0.2657, -0.1900,  0.1283,  ...,  0.1704,  0.0559, -0.0300],\n",
            "        ...,\n",
            "        [-0.1460, -0.0190,  0.1202,  ..., -0.0183, -0.3139,  0.1341],\n",
            "        [ 0.2220, -0.1614, -0.2988,  ..., -0.1062, -0.0632, -0.1443],\n",
            "        [ 0.3055,  0.2461,  0.1023,  ...,  0.3327, -0.1163,  0.0458]]), tensor([ 15.1411,  14.6134,  14.1424,  13.9631,  13.3046,  12.6810,\n",
            "         12.4371,  12.0242,  11.8428,  11.6152,  11.2177,  10.8304,\n",
            "         10.3587,  10.3029,   9.8450,   9.6898,   9.6456,   8.9049,\n",
            "          8.7255,   8.5374,   8.2846,   8.1343,   7.8017,   7.3512,\n",
            "          7.1137,   7.0597,   6.4487,   6.3200,   5.9941,   5.6144,\n",
            "          5.0583,   4.6069,   4.1461]), tensor([[-0.1338, -0.2807, -0.0237,  ...,  0.0353, -0.1370, -0.0378],\n",
            "        [-0.0823,  0.1078, -0.0177,  ..., -0.0443,  0.0238, -0.0460],\n",
            "        [-0.0873,  0.0032, -0.0781,  ...,  0.1854,  0.0386, -0.0173],\n",
            "        ...,\n",
            "        [ 0.0404, -0.0155,  0.0074,  ...,  0.0236,  0.0800,  0.0870],\n",
            "        [ 0.0192, -0.0266,  0.1160,  ...,  0.0602,  0.0334,  0.0039],\n",
            "        [-0.0632, -0.0806,  0.0085,  ..., -0.0616, -0.1102, -0.1939]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NEH6jjTMHlRX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "fF2x88AQtyev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "69ce7d25-3e5e-4f63-8862-79852741a508"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.randn(256, 256).cuda() # segmentation fault\n",
        "u, v, d = torch.svd(x)\n"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}